{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "k1gpzj4guo8e1riwj3om1k"
   },
   "source": [
    "### N-gram language models or how to write scientific papers (4 pts)\n",
    "\n",
    "We shall train our language model on a corpora of [ArXiv](http://arxiv.org/) articles and see if we can generate a new one!\n",
    "\n",
    "![img](https://media.npr.org/assets/img/2013/12/10/istock-18586699-monkey-computer_brick-16e5064d3378a14e0e4c2da08857efe03c04695e-s800-c85.jpg)\n",
    "\n",
    "_data by neelshah18 from [here](https://www.kaggle.com/neelshah18/arxivdataset/)_\n",
    "\n",
    "_Disclaimer: this has nothing to do with actual science. But it's fun, so who cares?!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "cellId": "u8jdaiy68oib3jvr4k01"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "0c76vnyl3zui9yhtkodgrlf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>day</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>month</th>\n",
       "      <th>summary</th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31609</th>\n",
       "      <td>[{'name': 'Kirill Gavrilyuk'}, {'name': 'Amir ...</td>\n",
       "      <td>20</td>\n",
       "      <td>1803.07485v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper strives for pixel-level segmentatio...</td>\n",
       "      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Actor and Action Video Segmentation from a Sen...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38596</th>\n",
       "      <td>[{'name': 'Luis Quesada'}, {'name': 'Alejandro...</td>\n",
       "      <td>16</td>\n",
       "      <td>1111.3969v2</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>11</td>\n",
       "      <td>3D motion tracking is a critical task in many ...</td>\n",
       "      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>The Object Projection Feature Estimation Probl...</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>[{'name': 'Shehroze Bhatti'}, {'name': 'Alban ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1612.00380v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>12</td>\n",
       "      <td>A number of recent approaches to policy learni...</td>\n",
       "      <td>[{'term': 'cs.AI', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Playing Doom with SLAM-Augmented Deep Reinforc...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21511</th>\n",
       "      <td>[{'name': 'Y. Goldberg'}, {'name': 'Y. Ritov'}]</td>\n",
       "      <td>16</td>\n",
       "      <td>0806.2669v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>6</td>\n",
       "      <td>We present the Procrustes measure, a novel mea...</td>\n",
       "      <td>[{'term': 'stat.ML', 'scheme': 'http://arxiv.o...</td>\n",
       "      <td>Local Procrustes for Manifold Embedding: A Mea...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13778</th>\n",
       "      <td>[{'name': \"Vladimir G. Red'ko\"}]</td>\n",
       "      <td>18</td>\n",
       "      <td>1411.5053v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>11</td>\n",
       "      <td>The model of interaction between learning and ...</td>\n",
       "      <td>[{'term': 'cs.NE', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Model of Interaction between Learning and Evol...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  author  day            id  \\\n",
       "31609  [{'name': 'Kirill Gavrilyuk'}, {'name': 'Amir ...   20  1803.07485v1   \n",
       "38596  [{'name': 'Luis Quesada'}, {'name': 'Alejandro...   16   1111.3969v2   \n",
       "1983   [{'name': 'Shehroze Bhatti'}, {'name': 'Alban ...    1  1612.00380v1   \n",
       "21511    [{'name': 'Y. Goldberg'}, {'name': 'Y. Ritov'}]   16   0806.2669v1   \n",
       "13778                   [{'name': \"Vladimir G. Red'ko\"}]   18   1411.5053v1   \n",
       "\n",
       "                                                    link  month  \\\n",
       "31609  [{'rel': 'alternate', 'href': 'http://arxiv.or...      3   \n",
       "38596  [{'rel': 'alternate', 'href': 'http://arxiv.or...     11   \n",
       "1983   [{'rel': 'alternate', 'href': 'http://arxiv.or...     12   \n",
       "21511  [{'rel': 'alternate', 'href': 'http://arxiv.or...      6   \n",
       "13778  [{'rel': 'alternate', 'href': 'http://arxiv.or...     11   \n",
       "\n",
       "                                                 summary  \\\n",
       "31609  This paper strives for pixel-level segmentatio...   \n",
       "38596  3D motion tracking is a critical task in many ...   \n",
       "1983   A number of recent approaches to policy learni...   \n",
       "21511  We present the Procrustes measure, a novel mea...   \n",
       "13778  The model of interaction between learning and ...   \n",
       "\n",
       "                                                     tag  \\\n",
       "31609  [{'term': 'cs.CV', 'scheme': 'http://arxiv.org...   \n",
       "38596  [{'term': 'cs.CV', 'scheme': 'http://arxiv.org...   \n",
       "1983   [{'term': 'cs.AI', 'scheme': 'http://arxiv.org...   \n",
       "21511  [{'term': 'stat.ML', 'scheme': 'http://arxiv.o...   \n",
       "13778  [{'term': 'cs.NE', 'scheme': 'http://arxiv.org...   \n",
       "\n",
       "                                                   title  year  \n",
       "31609  Actor and Action Video Segmentation from a Sen...  2018  \n",
       "38596  The Object Projection Feature Estimation Probl...  2011  \n",
       "1983   Playing Doom with SLAM-Augmented Deep Reinforc...  2016  \n",
       "21511  Local Procrustes for Manifold Embedding: A Mea...  2008  \n",
       "13778  Model of Interaction between Learning and Evol...  2014  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative manual download link: https://yadi.sk/d/_nGyU2IajjR9-w\n",
    "# !wget \"https://www.dropbox.com/s/99az9n1b57qkd9j/arxivData.json.tar.gz?dl=1\" -O arxivData.json.tar.gz\n",
    "# !tar -xvzf arxivData.json.tar.gz -C ./\n",
    "data = pd.read_json(\"./arxivData.json\")\n",
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "lbyqb5rx7j8jpo591r06ak"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Differential Contrastive Divergence ; This paper has been retracted.',\n",
       " 'What Does Artificial Life Tell Us About Death? ; Short philosophical essay',\n",
       " 'P=NP ; We claim to resolve the P=?NP problem via a formal argument for P=NP.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assemble lines: concatenate title and description\n",
    "lines = data.apply(lambda row: row['title'] + ' ; ' + row['summary'].replace('\\n', ' '), axis=1).tolist()\n",
    "sorted(lines, key=len)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7u97m5s8ekl5zd5a43a1yc"
   },
   "source": [
    "### Tokenization\n",
    "\n",
    "You know the dril. The data is messy. Go clean the data. Use WordPunctTokenizer or something.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellId": "u8rvfk719iek97t3rarwr"
   },
   "outputs": [],
   "source": [
    "# Task: convert lines (in-place) into strings of space-separated tokens. import & use WordPunctTokenizer\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "line_toks = [tokenizer.tokenize(line.lower()) for line in lines]\n",
    "lines = [\" \".join(line) for line in line_toks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "w88nddpp2k8edoeyyyjh0l"
   },
   "outputs": [],
   "source": [
    "assert sorted(lines, key=len)[0] == \\\n",
    "    'differential contrastive divergence ; this paper has been retracted .'\n",
    "assert sorted(lines, key=len)[2] == \\\n",
    "    'p = np ; we claim to resolve the p =? np problem via a formal argument for p = np .'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "qb6h3hxmr095egzv8rlzul"
   },
   "source": [
    "### N-Gram Language Model (1point)\n",
    "\n",
    "A language model is a probabilistic model that estimates text probability: the joint probability of all tokens $w_t$ in text $X$: $P(X) = P(w_1, \\dots, w_T)$.\n",
    "\n",
    "It can do so by following the chain rule:\n",
    "$$P(w_1, \\dots, w_T) = P(w_1)P(w_2 \\mid w_1)\\dots P(w_T \\mid w_1, \\dots, w_{T-1}).$$ \n",
    "\n",
    "The problem with such approach is that the final term $P(w_T \\mid w_1, \\dots, w_{T-1})$ depends on $n-1$ previous words. This probability is impractical to estimate for long texts, e.g. $T = 1000$.\n",
    "\n",
    "One popular approximation is to assume that next word only depends on a finite amount of previous words:\n",
    "\n",
    "$$P(w_t \\mid w_1, \\dots, w_{t - 1}) = P(w_t \\mid w_{t - n + 1}, \\dots, w_{t - 1})$$\n",
    "\n",
    "Such model is called __n-gram language model__ where n is a parameter. For example, in 3-gram language model, each word only depends on 2 previous words. \n",
    "\n",
    "$$\n",
    "    P(w_1, \\dots, w_n) = \\prod_t P(w_t \\mid w_{t - n + 1}, \\dots, w_{t - 1}).\n",
    "$$\n",
    "\n",
    "You can also sometimes see such approximation under the name of _n-th order markov assumption_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "u68wydbiioqlp5gl96mhd"
   },
   "source": [
    "The first stage to building such a model is counting all word occurences given N-1 previous words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellId": "og84gjipnumsakhiiu9ap"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# special tokens: \n",
    "# - unk represents absent tokens, \n",
    "# - eos is a special token after the end of sequence\n",
    "\n",
    "UNK, EOS = \"_UNK_\", \"_EOS_\"\n",
    "\n",
    "def count_ngrams(lines, n):\n",
    "\t\"\"\"\n",
    "\tCount how many times each word occured after (n - 1) previous words\n",
    "\t:param lines: an iterable of strings with space-separated tokens\n",
    "\t:returns: a dictionary { tuple(prefix_tokens): {next_token_1: count_1, next_token_2: count_2}}\n",
    "\n",
    "\tWhen building counts, please consider the following two edge cases\n",
    "\t- if prefix is shorter than (n - 1) tokens, it should be padded with UNK. For n=3,\n",
    "\tempty prefix: \"\" -> (UNK, UNK)\n",
    "\tshort prefix: \"the\" -> (UNK, the)\n",
    "\tlong prefix: \"the new approach\" -> (new, approach)\n",
    "\t- you should add a special token, EOS, at the end of each sequence\n",
    "\t\"... with deep neural networks .\" -> (..., with, deep, neural, networks, ., EOS)\n",
    "\tcount the probability of this token just like all others.\n",
    "\t\"\"\"\n",
    "\tcounts = defaultdict(Counter) \n",
    "\t# counts[(word1, word2)][word3] = how many times word3 occured after (word1, word2)\n",
    "\n",
    "\tlines = [line.split(\" \") for line in lines]\n",
    "\tlines = [[UNK]*2 + line + [EOS] for line in lines]\n",
    "\n",
    "\tfor line_number in tqdm(range(len(lines))):\n",
    "\t\tline = lines[line_number]\n",
    "\t\ti = n-1\n",
    "\t\twhile i<len(line):\n",
    "\t\t\tcounts[tuple(line[i-k] for k in range(n-1,0,-1))][line[i]]+=1\n",
    "\t\t\ti+=1\n",
    "\n",
    "\treturn dict(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellId": "xyf2he6lak9mmqarl3nck"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 12521.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# let's test it\n",
    "dummy_lines = sorted(lines, key=len)[:100]\n",
    "dummy_counts = count_ngrams(dummy_lines, n=3)\n",
    "assert set(map(len, dummy_counts.keys())) == {2}, \"please only count {n-1}-grams\"\n",
    "assert len(dummy_counts[('_UNK_', '_UNK_')]) == 78 # check these, not sure what they're after\n",
    "assert dummy_counts['_UNK_', 'a']['note'] == 3\n",
    "assert dummy_counts['p', '=']['np'] == 2\n",
    "assert dummy_counts['author', '.']['_EOS_'] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4j620npeqvj0k8ak8xqx8xk"
   },
   "source": [
    "Once we can count N-grams, we can build a probabilistic language model.\n",
    "The simplest way to compute probabilities is in proporiton to counts:\n",
    "\n",
    "$$ P(w_t | prefix) = { Count(prefix, w_t) \\over \\sum_{\\hat w} Count(prefix, \\hat w) } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cellId": "c7cm76wmzlaa12bctznzei"
   },
   "outputs": [],
   "source": [
    "class NGramLanguageModel:    \n",
    "    def __init__(self, lines, n):\n",
    "        \"\"\" \n",
    "        Train a simple count-based language model: \n",
    "        compute probabilities P(w_t | prefix) given ngram counts\n",
    "        \n",
    "        :param n: computes probability of next token given (n - 1) previous words\n",
    "        :param lines: an iterable of strings with space-separated tokens\n",
    "        \"\"\"\n",
    "        assert n >= 1\n",
    "        self.n = n\n",
    "    \n",
    "        counts = count_ngrams(lines, self.n)\n",
    "        \n",
    "        # compute token proabilities given counts\n",
    "        self.probs = defaultdict(Counter)\n",
    "        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n",
    "        \n",
    "        # populate self.probs with actual probabilities\n",
    "        for prefix, counter in counts.items():\n",
    "            for word in counter:\n",
    "                self.probs[prefix][word] = counts[prefix][word] / sum(counts[prefix].values()) # turn the count for a word into a probability\n",
    "            \n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :returns: a dictionary {token : it's probability} for all tokens with positive probabilities\n",
    "        \"\"\"\n",
    "        prefix = prefix.split()\n",
    "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
    "        prefix = [ UNK ] * (self.n - 1 - len(prefix)) + prefix\n",
    "        return self.probs[tuple(prefix)]\n",
    "    \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :param next_token: the next token to predict probability for\n",
    "        :returns: P(next_token|prefix) a single number, 0 <= P <= 1\n",
    "        \"\"\"\n",
    "        return self.get_possible_next_tokens(prefix).get(next_token, 0) # if the key doesn't exist, return zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "0ftnn4nmuzrup6c0vvhb8q"
   },
   "source": [
    "Let's test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cellId": "a7zajcnvhqupvcrmacvkur"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 5970.11it/s]\n"
     ]
    }
   ],
   "source": [
    "dummy_lm = NGramLanguageModel(dummy_lines, n=3)\n",
    "\n",
    "p_initial = dummy_lm.get_possible_next_tokens('') # '' -> ['_UNK_', '_UNK_']\n",
    "assert np.allclose(p_initial['learning'], 0.02)\n",
    "assert np.allclose(p_initial['a'], 0.13)\n",
    "assert np.allclose(p_initial.get('meow', 0), 0)\n",
    "assert np.allclose(sum(p_initial.values()), 1) # checking normalisation\n",
    "\n",
    "p_a = dummy_lm.get_possible_next_tokens('a') # '' -> ['_UNK_', 'a']\n",
    "assert np.allclose(p_a['machine'], 0.15384615)\n",
    "assert np.allclose(p_a['note'], 0.23076923)\n",
    "assert np.allclose(p_a.get('the', 0), 0)\n",
    "assert np.allclose(sum(p_a.values()), 1)\n",
    "\n",
    "assert np.allclose(dummy_lm.get_possible_next_tokens('a note')['on'], 1)\n",
    "assert dummy_lm.get_possible_next_tokens('a machine') == \\\n",
    "    dummy_lm.get_possible_next_tokens(\"there have always been ghosts in a machine\")  # \"your 3-gram model should only depend on 2 previous words\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "oh8r9a41kuk4r51wra9"
   },
   "source": [
    "Now that you've got a working n-gram language model, let's see what sequences it can generate. But first, let's train it on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "cellId": "f17xoejjppmooo2nopw4xo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41000/41000 [00:23<00:00, 1727.93it/s]\n"
     ]
    }
   ],
   "source": [
    "lm = NGramLanguageModel(lines, n=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "2kd9glwnkr470qc4bt7f1e"
   },
   "source": [
    "The process of generating sequences is... well, it's sequential. You maintain a list of tokens and iteratively add next token by sampling with probabilities.\n",
    "\n",
    "$ X = [] $\n",
    "\n",
    "__forever:__\n",
    "* $w_{next} \\sim P(w_{next} | X)$\n",
    "* $X = concat(X, w_{next})$\n",
    "\n",
    "\n",
    "Instead of sampling with probabilities, one can also try always taking most likely token, sampling among top-K most likely tokens or sampling with temperature. In the latter case (temperature), one samples from\n",
    "\n",
    "$$w_{next} \\sim {P(w_{next} | X) ^ {1 / \\tau} \\over \\sum_{\\hat w} P(\\hat w | X) ^ {1 / \\tau}}$$\n",
    "\n",
    "Where $\\tau > 0$ is model temperature. If $\\tau << 1$, more likely tokens will be sampled with even higher probability while less likely tokens will vanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'deep': 0.022139070782662924,\n",
       "         'unified': 0.019020891799189272,\n",
       "         'systematic': 0.002182725288431556,\n",
       "         'network': 0.0018709073900841909,\n",
       "         'factorization': 0.0009354536950420954,\n",
       "         'new': 0.05207358902400998,\n",
       "         'neural': 0.011849080137199874,\n",
       "         'hierarchical': 0.004989086373557842,\n",
       "         'structured': 0.0018709073900841909,\n",
       "         'recurrent': 0.0012472715933894605,\n",
       "         'joint': 0.002806361085126286,\n",
       "         'latent': 0.002806361085126286,\n",
       "         'pso': 0.0003118178983473651,\n",
       "         'simple': 0.01216089803554724,\n",
       "         'general': 0.01278453383224197,\n",
       "         'probabilistic': 0.01216089803554724,\n",
       "         'rotation': 0.0006236357966947302,\n",
       "         'classification': 0.0015590894917368258,\n",
       "         'supervised': 0.002182725288431556,\n",
       "         'multi': 0.0134081696289367,\n",
       "         'convolutional': 0.002494543186778921,\n",
       "         'generalization': 0.0012472715933894605,\n",
       "         'brief': 0.004365450576863112,\n",
       "         'survey': 0.024009978172747116,\n",
       "         'machine': 0.005300904271905207,\n",
       "         'novel': 0.04303086997193639,\n",
       "         'data': 0.004989086373557842,\n",
       "         'constrained': 0.0009354536950420954,\n",
       "         'physical': 0.0003118178983473651,\n",
       "         'benchmarking': 0.0003118178983473651,\n",
       "         'focused': 0.0003118178983473651,\n",
       "         'fixed': 0.0009354536950420954,\n",
       "         'semisupervised': 0.0003118178983473651,\n",
       "         're': 0.0003118178983473651,\n",
       "         'dependency': 0.0009354536950420954,\n",
       "         'sensitivity': 0.0009354536950420954,\n",
       "         'comprehensive': 0.005612722170252572,\n",
       "         'continuous': 0.0015590894917368258,\n",
       "         'note': 0.01153726223885251,\n",
       "         'geometric': 0.0037418147801683817,\n",
       "         'compact': 0.002182725288431556,\n",
       "         'stochastic': 0.004053632678515747,\n",
       "         'high': 0.0015590894917368258,\n",
       "         'growing': 0.0003118178983473651,\n",
       "         'genetic': 0.0037418147801683817,\n",
       "         'flow': 0.0003118178983473651,\n",
       "         'bayesian': 0.01652634861241035,\n",
       "         'group': 0.0003118178983473651,\n",
       "         'generative': 0.006236357966947303,\n",
       "         'method': 0.006236357966947303,\n",
       "         'scalable': 0.0034299968818210166,\n",
       "         'hybrid': 0.01777362020579981,\n",
       "         'mathematical': 0.0034299968818210166,\n",
       "         'theory': 0.004365450576863112,\n",
       "         'review': 0.007483629560336763,\n",
       "         'guide': 0.0003118178983473651,\n",
       "         'cheap': 0.0006236357966947302,\n",
       "         'deterministic': 0.0009354536950420954,\n",
       "         'pca': 0.0006236357966947302,\n",
       "         'visual': 0.0018709073900841909,\n",
       "         'powerful': 0.0003118178983473651,\n",
       "         'single': 0.0009354536950420954,\n",
       "         'baseline': 0.0003118178983473651,\n",
       "         'distance': 0.002182725288431556,\n",
       "         'modular': 0.0006236357966947302,\n",
       "         'sequential': 0.0018709073900841909,\n",
       "         'user': 0.0006236357966947302,\n",
       "         'multichannel': 0.0003118178983473651,\n",
       "         'large': 0.005612722170252572,\n",
       "         'case': 0.002494543186778921,\n",
       "         'linear': 0.004677268475210477,\n",
       "         'random': 0.002494543186778921,\n",
       "         \"'\": 0.0003118178983473651,\n",
       "         'regularized': 0.0003118178983473651,\n",
       "         'flexible': 0.0034299968818210166,\n",
       "         'semi': 0.004365450576863112,\n",
       "         'fast': 0.010601808543810414,\n",
       "         'reduction': 0.0006236357966947302,\n",
       "         'variational': 0.002806361085126286,\n",
       "         'meta': 0.0006236357966947302,\n",
       "         'critical': 0.0018709073900841909,\n",
       "         'pac': 0.0009354536950420954,\n",
       "         'useful': 0.0003118178983473651,\n",
       "         'practically': 0.0003118178983473651,\n",
       "         'learning': 0.004365450576863112,\n",
       "         'convex': 0.004365450576863112,\n",
       "         'branch': 0.0009354536950420954,\n",
       "         'greedy': 0.0015590894917368258,\n",
       "         'generalized': 0.005924540068599937,\n",
       "         'non': 0.005612722170252572,\n",
       "         'robust': 0.008107265357031494,\n",
       "         'sparse': 0.0009354536950420954,\n",
       "         'gauss': 0.0003118178983473651,\n",
       "         'minimalistic': 0.0003118178983473651,\n",
       "         'subsequence': 0.0003118178983473651,\n",
       "         'local': 0.0009354536950420954,\n",
       "         'shallow': 0.0003118178983473651,\n",
       "         'quantitative': 0.0015590894917368258,\n",
       "         '-': 0.0012472715933894605,\n",
       "         'distributional': 0.0006236357966947302,\n",
       "         'framework': 0.015279077019020891,\n",
       "         'change': 0.0003118178983473651,\n",
       "         'semantic': 0.004053632678515747,\n",
       "         'combinatorial': 0.0012472715933894605,\n",
       "         'dataset': 0.002182725288431556,\n",
       "         'privacy': 0.0003118178983473651,\n",
       "         'slice': 0.0003118178983473651,\n",
       "         'multiscale': 0.0006236357966947302,\n",
       "         'diffusion': 0.0006236357966947302,\n",
       "         'bi': 0.0009354536950420954,\n",
       "         'comparative': 0.01278453383224197,\n",
       "         'recursive': 0.0006236357966947302,\n",
       "         'stable': 0.0003118178983473651,\n",
       "         'theoretical': 0.0037418147801683817,\n",
       "         'rapid': 0.0003118178983473651,\n",
       "         'statistical': 0.007171811661989398,\n",
       "         'more': 0.0009354536950420954,\n",
       "         'nonlinear': 0.0009354536950420954,\n",
       "         'fully': 0.0034299968818210166,\n",
       "         'connection': 0.0006236357966947302,\n",
       "         'forward': 0.0003118178983473651,\n",
       "         'dirt': 0.0003118178983473651,\n",
       "         'mixture': 0.0009354536950420954,\n",
       "         'poisson': 0.0003118178983473651,\n",
       "         'monte': 0.0006236357966947302,\n",
       "         'permutation': 0.0006236357966947302,\n",
       "         'spectral': 0.002806361085126286,\n",
       "         'discipline': 0.0003118178983473651,\n",
       "         'short': 0.0034299968818210166,\n",
       "         'practical': 0.002494543186778921,\n",
       "         'study': 0.013719987527284067,\n",
       "         'recommender': 0.0006236357966947302,\n",
       "         'step': 0.0009354536950420954,\n",
       "         'nonclassical': 0.0003118178983473651,\n",
       "         'competitive': 0.0003118178983473651,\n",
       "         'restricted': 0.0003118178983473651,\n",
       "         'diagram': 0.0003118178983473651,\n",
       "         'harmonic': 0.0003118178983473651,\n",
       "         'causal': 0.0006236357966947302,\n",
       "         'hebbian': 0.0009354536950420954,\n",
       "         'state': 0.002494543186778921,\n",
       "         'digital': 0.0006236357966947302,\n",
       "         'relativistic': 0.0003118178983473651,\n",
       "         'fusion': 0.0018709073900841909,\n",
       "         'solution': 0.0012472715933894605,\n",
       "         'discriminative': 0.0015590894917368258,\n",
       "         'cascaded': 0.0006236357966947302,\n",
       "         'formal': 0.004365450576863112,\n",
       "         'foundation': 0.0003118178983473651,\n",
       "         'kernel': 0.004053632678515747,\n",
       "         'methodology': 0.0012472715933894605,\n",
       "         'multivariate': 0.0003118178983473651,\n",
       "         'minimum': 0.0009354536950420954,\n",
       "         'convergent': 0.0003118178983473651,\n",
       "         'time': 0.0006236357966947302,\n",
       "         'parameter': 0.0006236357966947302,\n",
       "         'conditional': 0.0006236357966947302,\n",
       "         'computational': 0.006859993763642033,\n",
       "         'mixed': 0.0009354536950420954,\n",
       "         'characterization': 0.0018709073900841909,\n",
       "         'rigorously': 0.0003118178983473651,\n",
       "         'two': 0.004365450576863112,\n",
       "         'compositional': 0.0009354536950420954,\n",
       "         'base': 0.0003118178983473651,\n",
       "         'parallel': 0.004677268475210477,\n",
       "         'comparison': 0.009978172747115684,\n",
       "         'weakly': 0.0006236357966947302,\n",
       "         'behavior': 0.0006236357966947302,\n",
       "         'spacetime': 0.0003118178983473651,\n",
       "         'laplacian': 0.0003118178983473651,\n",
       "         'first': 0.0018709073900841909,\n",
       "         'generic': 0.002182725288431556,\n",
       "         'deeper': 0.0006236357966947302,\n",
       "         'bio': 0.0015590894917368258,\n",
       "         'radically': 0.0003118178983473651,\n",
       "         'self': 0.004053632678515747,\n",
       "         'tutorial': 0.0037418147801683817,\n",
       "         'unifying': 0.002494543186778921,\n",
       "         'reliable': 0.0006236357966947302,\n",
       "         'metric': 0.0015590894917368258,\n",
       "         'family': 0.0009354536950420954,\n",
       "         'regularization': 0.0006236357966947302,\n",
       "         'lipschitz': 0.0003118178983473651,\n",
       "         'conjugate': 0.0003118178983473651,\n",
       "         'widely': 0.0003118178983473651,\n",
       "         'convergence': 0.0012472715933894605,\n",
       "         'randomized': 0.0015590894917368258,\n",
       "         'function': 0.0003118178983473651,\n",
       "         'differentiable': 0.0003118178983473651,\n",
       "         'reconstruction': 0.0003118178983473651,\n",
       "         'binary': 0.0012472715933894605,\n",
       "         'split': 0.0003118178983473651,\n",
       "         'dantzig': 0.0003118178983473651,\n",
       "         'concentration': 0.0003118178983473651,\n",
       "         'class': 0.0018709073900841909,\n",
       "         'conformal': 0.0003118178983473651,\n",
       "         'budget': 0.0003118178983473651,\n",
       "         'graph': 0.002494543186778921,\n",
       "         'model': 0.008107265357031494,\n",
       "         'scaled': 0.0006236357966947302,\n",
       "         'batch': 0.0006236357966947302,\n",
       "         'tight': 0.0012472715933894605,\n",
       "         'strongly': 0.0003118178983473651,\n",
       "         'boundary': 0.0003118178983473651,\n",
       "         'category': 0.0006236357966947302,\n",
       "         'benchmark': 0.002182725288431556,\n",
       "         'dirichlet': 0.0003118178983473651,\n",
       "         'modified': 0.0018709073900841909,\n",
       "         'description': 0.0006236357966947302,\n",
       "         'gamp': 0.0003118178983473651,\n",
       "         'dual': 0.002806361085126286,\n",
       "         'riemannian': 0.0006236357966947302,\n",
       "         'siamese': 0.0003118178983473651,\n",
       "         'closer': 0.0006236357966947302,\n",
       "         'divergence': 0.0006236357966947302,\n",
       "         'giant': 0.0003118178983473651,\n",
       "         'variance': 0.0006236357966947302,\n",
       "         'textual': 0.0003118178983473651,\n",
       "         'disentangled': 0.0003118178983473651,\n",
       "         'correction': 0.0003118178983473651,\n",
       "         'universal': 0.0018709073900841909,\n",
       "         'separation': 0.0006236357966947302,\n",
       "         'resizable': 0.0003118178983473651,\n",
       "         'classifying': 0.0003118178983473651,\n",
       "         'global': 0.0015590894917368258,\n",
       "         'trans': 0.0003118178983473651,\n",
       "         'bridge': 0.0003118178983473651,\n",
       "         'predictive': 0.0015590894917368258,\n",
       "         'game': 0.0018709073900841909,\n",
       "         'walk': 0.0003118178983473651,\n",
       "         'representer': 0.0003118178983473651,\n",
       "         'bag': 0.0012472715933894605,\n",
       "         'minimax': 0.0015590894917368258,\n",
       "         'spiking': 0.0006236357966947302,\n",
       "         'max': 0.0003118178983473651,\n",
       "         'quantum': 0.0018709073900841909,\n",
       "         'dynamic': 0.004053632678515747,\n",
       "         'numerical': 0.0006236357966947302,\n",
       "         'complete': 0.0037418147801683817,\n",
       "         'controller': 0.0003118178983473651,\n",
       "         'convnet': 0.0003118178983473651,\n",
       "         'paraboost': 0.0003118178983473651,\n",
       "         'learned': 0.0003118178983473651,\n",
       "         'strategy': 0.0003118178983473651,\n",
       "         'downsampled': 0.0003118178983473651,\n",
       "         'multitask': 0.0003118178983473651,\n",
       "         'pitfall': 0.0006236357966947302,\n",
       "         'spatial': 0.0012472715933894605,\n",
       "         'feature': 0.004053632678515747,\n",
       "         'frobenius': 0.0003118178983473651,\n",
       "         'logic': 0.004677268475210477,\n",
       "         'generalised': 0.0012472715933894605,\n",
       "         'system': 0.0012472715933894605,\n",
       "         'retrieval': 0.0003118178983473651,\n",
       "         'consumer': 0.0003118178983473651,\n",
       "         'uniform': 0.0009354536950420954,\n",
       "         'subband': 0.0003118178983473651,\n",
       "         'curriculum': 0.0003118178983473651,\n",
       "         'cascade': 0.0003118178983473651,\n",
       "         'junction': 0.0003118178983473651,\n",
       "         'nonparametric': 0.002494543186778921,\n",
       "         'compilation': 0.0003118178983473651,\n",
       "         'categorical': 0.0003118178983473651,\n",
       "         'rational': 0.0009354536950420954,\n",
       "         'tube': 0.0003118178983473651,\n",
       "         'plea': 0.0003118178983473651,\n",
       "         'better': 0.0006236357966947302,\n",
       "         'selection': 0.0003118178983473651,\n",
       "         'searchlight': 0.0003118178983473651,\n",
       "         'fatal': 0.0003118178983473651,\n",
       "         'reactive': 0.0003118178983473651,\n",
       "         'unit': 0.0003118178983473651,\n",
       "         'contextual': 0.0003118178983473651,\n",
       "         'dirty': 0.0003118178983473651,\n",
       "         'history': 0.0006236357966947302,\n",
       "         'triclustering': 0.0003118178983473651,\n",
       "         'linearly': 0.0006236357966947302,\n",
       "         'correlation': 0.0009354536950420954,\n",
       "         'gang': 0.0003118178983473651,\n",
       "         'balanced': 0.0003118178983473651,\n",
       "         'sufficient': 0.0003118178983473651,\n",
       "         'low': 0.002806361085126286,\n",
       "         'discussion': 0.0006236357966947302,\n",
       "         'submodular': 0.0003118178983473651,\n",
       "         'clustering': 0.0012472715933894605,\n",
       "         'graphical': 0.0009354536950420954,\n",
       "         'topic': 0.0006236357966947302,\n",
       "         'simpler': 0.0006236357966947302,\n",
       "         'tensor': 0.0003118178983473651,\n",
       "         'primal': 0.0006236357966947302,\n",
       "         'boosting': 0.0009354536950420954,\n",
       "         'second': 0.0003118178983473651,\n",
       "         'consistent': 0.0009354536950420954,\n",
       "         'partan': 0.0003118178983473651,\n",
       "         'noise': 0.0003118178983473651,\n",
       "         'one': 0.0003118178983473651,\n",
       "         'hidden': 0.0006236357966947302,\n",
       "         'regression': 0.0006236357966947302,\n",
       "         'distributed': 0.002494543186778921,\n",
       "         'plug': 0.0003118178983473651,\n",
       "         'cost': 0.0006236357966947302,\n",
       "         'compressed': 0.0003118178983473651,\n",
       "         'primer': 0.0009354536950420954,\n",
       "         'sub': 0.0009354536950420954,\n",
       "         'geometrical': 0.0003118178983473651,\n",
       "         'smart': 0.0003118178983473651,\n",
       "         'hitting': 0.0003118178983473651,\n",
       "         'goal': 0.0006236357966947302,\n",
       "         'converse': 0.0003118178983473651,\n",
       "         'proof': 0.0006236357966947302,\n",
       "         'maximum': 0.0009354536950420954,\n",
       "         'well': 0.0006236357966947302,\n",
       "         'bootstrap': 0.0006236357966947302,\n",
       "         'compressive': 0.0003118178983473651,\n",
       "         'quasi': 0.0009354536950420954,\n",
       "         'versatile': 0.0006236357966947302,\n",
       "         'correspondence': 0.0009354536950420954,\n",
       "         'markov': 0.0009354536950420954,\n",
       "         'big': 0.0003118178983473651,\n",
       "         'progressive': 0.0003118178983473651,\n",
       "         'likelihood': 0.0006236357966947302,\n",
       "         'pathway': 0.0003118178983473651,\n",
       "         'hajj': 0.0003118178983473651,\n",
       "         'series': 0.0003118178983473651,\n",
       "         'taxonomy': 0.0006236357966947302,\n",
       "         'perspective': 0.0012472715933894605,\n",
       "         'gpu': 0.0003118178983473651,\n",
       "         'sequence': 0.0006236357966947302,\n",
       "         'decentralized': 0.0003118178983473651,\n",
       "         'philosophical': 0.0003118178983473651,\n",
       "         'dissipative': 0.0003118178983473651,\n",
       "         'gibbs': 0.0003118178983473651,\n",
       "         'constructive': 0.0003118178983473651,\n",
       "         'neuro': 0.0012472715933894605,\n",
       "         'neuromorphic': 0.0009354536950420954,\n",
       "         'cumulative': 0.0003118178983473651,\n",
       "         'radial': 0.0003118178983473651,\n",
       "         'process': 0.0003118178983473651,\n",
       "         'swarm': 0.0003118178983473651,\n",
       "         'heuristic': 0.002182725288431556,\n",
       "         'cooperative': 0.0006236357966947302,\n",
       "         'cmos': 0.0006236357966947302,\n",
       "         'polynomial': 0.002182725288431556,\n",
       "         'connectionist': 0.0003118178983473651,\n",
       "         'parameterized': 0.0009354536950420954,\n",
       "         'physarum': 0.0003118178983473651,\n",
       "         'memetic': 0.0003118178983473651,\n",
       "         'social': 0.0006236357966947302,\n",
       "         'preliminary': 0.0012472715933894605,\n",
       "         'natural': 0.0012472715933894605,\n",
       "         'computationally': 0.0003118178983473651,\n",
       "         'proposed': 0.0006236357966947302,\n",
       "         'cuda': 0.0003118178983473651,\n",
       "         'trainable': 0.0003118178983473651,\n",
       "         'cognitive': 0.0015590894917368258,\n",
       "         'telescopic': 0.0003118178983473651,\n",
       "         'reconfigurable': 0.0006236357966947302,\n",
       "         'fuzzy': 0.006548175865294668,\n",
       "         'continuum': 0.0006236357966947302,\n",
       "         'draft': 0.0003118178983473651,\n",
       "         'brownian': 0.0003118178983473651,\n",
       "         'software': 0.0006236357966947302,\n",
       "         'search': 0.0003118178983473651,\n",
       "         'sport': 0.0003118178983473651,\n",
       "         'divide': 0.0006236357966947302,\n",
       "         'many': 0.0003118178983473651,\n",
       "         'batching': 0.0003118178983473651,\n",
       "         'particle': 0.0006236357966947302,\n",
       "         'mullti': 0.0003118178983473651,\n",
       "         'lexicalized': 0.0003118178983473651,\n",
       "         'freely': 0.0003118178983473651,\n",
       "         'real': 0.002806361085126286,\n",
       "         'finite': 0.0009354536950420954,\n",
       "         'tableaux': 0.0003118178983473651,\n",
       "         'novelty': 0.0003118178983473651,\n",
       "         'decision': 0.002494543186778921,\n",
       "         'bit': 0.0003118178983473651,\n",
       "         'procedure': 0.0003118178983473651,\n",
       "         'variable': 0.0003118178983473651,\n",
       "         'chart': 0.0003118178983473651,\n",
       "         'cross': 0.0006236357966947302,\n",
       "         'public': 0.0006236357966947302,\n",
       "         'bimachine': 0.0003118178983473651,\n",
       "         'sentimental': 0.0003118178983473651,\n",
       "         'matter': 0.0006236357966947302,\n",
       "         'toolkit': 0.0003118178983473651,\n",
       "         'chain': 0.0009354536950420954,\n",
       "         'discourse': 0.0006236357966947302,\n",
       "         'pdtb': 0.0003118178983473651,\n",
       "         'concise': 0.0003118178983473651,\n",
       "         'constraint': 0.002806361085126286,\n",
       "         'corpus': 0.002182725288431556,\n",
       "         'layered': 0.0003118178983473651,\n",
       "         'common': 0.0009354536950420954,\n",
       "         'literature': 0.0009354536950420954,\n",
       "         'noisy': 0.0003118178983473651,\n",
       "         'lightweight': 0.0012472715933894605,\n",
       "         'prototype': 0.0012472715933894605,\n",
       "         'character': 0.0006236357966947302,\n",
       "         'crf': 0.0003118178983473651,\n",
       "         'resource': 0.0006236357966947302,\n",
       "         'principled': 0.0009354536950420954,\n",
       "         'morphological': 0.0003118178983473651,\n",
       "         'modality': 0.0003118178983473651,\n",
       "         'text': 0.0003118178983473651,\n",
       "         'knowledge': 0.0037418147801683817,\n",
       "         'publicly': 0.0003118178983473651,\n",
       "         'complex': 0.0003118178983473651,\n",
       "         'commentary': 0.0003118178983473651,\n",
       "         'light': 0.0015590894917368258,\n",
       "         'diversity': 0.0003118178983473651,\n",
       "         'chinese': 0.0006236357966947302,\n",
       "         'multilingual': 0.0006236357966947302,\n",
       "         'c': 0.0006236357966947302,\n",
       "         'planning': 0.0006236357966947302,\n",
       "         'readability': 0.0003118178983473651,\n",
       "         'persona': 0.0003118178983473651,\n",
       "         'readable': 0.0003118178983473651,\n",
       "         'proposal': 0.0015590894917368258,\n",
       "         'decomposable': 0.0003118178983473651,\n",
       "         'correlational': 0.0003118178983473651,\n",
       "         'piece': 0.0003118178983473651,\n",
       "         'sentence': 0.0009354536950420954,\n",
       "         'pragmatic': 0.0003118178983473651,\n",
       "         'strong': 0.0003118178983473651,\n",
       "         'context': 0.0009354536950420954,\n",
       "         'dictionary': 0.0003118178983473651,\n",
       "         'factorized': 0.0006236357966947302,\n",
       "         'tentative': 0.0003118178983473651,\n",
       "         'paradigm': 0.0006236357966947302,\n",
       "         'theme': 0.0003118178983473651,\n",
       "         'fofe': 0.0003118178983473651,\n",
       "         'surrogate': 0.0003118178983473651,\n",
       "         'pos': 0.0003118178983473651,\n",
       "         'multifaceted': 0.0003118178983473651,\n",
       "         'morphology': 0.0003118178983473651,\n",
       "         'stylometric': 0.0003118178983473651,\n",
       "         'world': 0.0003118178983473651,\n",
       "         'transition': 0.0003118178983473651,\n",
       "         'trolling': 0.0003118178983473651,\n",
       "         'broad': 0.0003118178983473651,\n",
       "         '*': 0.0003118178983473651,\n",
       "         'trie': 0.0003118178983473651,\n",
       "         'challenge': 0.0003118178983473651,\n",
       "         'gru': 0.0006236357966947302,\n",
       "         'teacher': 0.0003118178983473651,\n",
       "         'minimal': 0.0015590894917368258,\n",
       "         'biomedical': 0.0003118178983473651,\n",
       "         'frame': 0.0003118178983473651,\n",
       "         'full': 0.0003118178983473651,\n",
       "         'nested': 0.0006236357966947302,\n",
       "         'critique': 0.0003118178983473651,\n",
       "         'pilot': 0.0003118178983473651,\n",
       "         'continuously': 0.0003118178983473651,\n",
       "         'syllable': 0.0003118178983473651,\n",
       "         'question': 0.0006236357966947302,\n",
       "         'rule': 0.0009354536950420954,\n",
       "         'recorded': 0.0003118178983473651,\n",
       "         'bimodal': 0.0006236357966947302,\n",
       "         'web': 0.0012472715933894605,\n",
       "         'very': 0.0003118178983473651,\n",
       "         'semantically': 0.0003118178983473651,\n",
       "         'gap': 0.0003118178983473651,\n",
       "         'syntactic': 0.0006236357966947302,\n",
       "         'practitioners': 0.0003118178983473651,\n",
       "         'multilayer': 0.0006236357966947302,\n",
       "         'sheaf': 0.0003118178983473651,\n",
       "         'factoid': 0.0003118178983473651,\n",
       "         'market': 0.0003118178983473651,\n",
       "         'semantics': 0.0006236357966947302,\n",
       "         'domain': 0.0006236357966947302,\n",
       "         'hierarchy': 0.0003118178983473651,\n",
       "         'selective': 0.0003118178983473651,\n",
       "         'reusable': 0.0003118178983473651,\n",
       "         'compiler': 0.0003118178983473651,\n",
       "         'splitting': 0.0003118178983473651,\n",
       "         'consistency': 0.0003118178983473651,\n",
       "         'ternary': 0.0006236357966947302,\n",
       "         'concurrent': 0.0003118178983473651,\n",
       "         'neutrosophic': 0.0006236357966947302,\n",
       "         'collection': 0.0003118178983473651,\n",
       "         'leaf': 0.0003118178983473651,\n",
       "         'necessary': 0.0003118178983473651,\n",
       "         'soft': 0.0003118178983473651,\n",
       "         'formalization': 0.0006236357966947302,\n",
       "         'wiki': 0.0003118178983473651,\n",
       "         'directional': 0.0006236357966947302,\n",
       "         'temporal': 0.0012472715933894605,\n",
       "         'counter': 0.0003118178983473651,\n",
       "         'behavioral': 0.0003118178983473651,\n",
       "         'multiagent': 0.0012472715933894605,\n",
       "         'delayed': 0.0003118178983473651,\n",
       "         'matrix': 0.0006236357966947302,\n",
       "         'forgetting': 0.0003118178983473651,\n",
       "         'paraconsistent': 0.0006236357966947302,\n",
       "         'calculus': 0.0003118178983473651,\n",
       "         'tractable': 0.0006236357966947302,\n",
       "         'differential': 0.0012472715933894605,\n",
       "         'qualitative': 0.0006236357966947302,\n",
       "         'possibilistic': 0.0003118178983473651,\n",
       "         'combination': 0.0003118178983473651,\n",
       "         'logical': 0.0012472715933894605,\n",
       "         'representation': 0.0006236357966947302,\n",
       "         'measure': 0.0003118178983473651,\n",
       "         'backwards': 0.0003118178983473651,\n",
       "         'vlsi': 0.0003118178983473651,\n",
       "         'cure': 0.0003118178983473651,\n",
       "         'novice': 0.0006236357966947302,\n",
       "         'decomposition': 0.0003118178983473651,\n",
       "         'maximal': 0.0009354536950420954,\n",
       "         'typed': 0.0003118178983473651,\n",
       "         'protocol': 0.0003118178983473651,\n",
       "         'partial': 0.0003118178983473651,\n",
       "         'definition': 0.0003118178983473651,\n",
       "         'cluster': 0.0006236357966947302,\n",
       "         'biomimetic': 0.0006236357966947302,\n",
       "         'simplified': 0.0006236357966947302,\n",
       "         'revision': 0.0003118178983473651,\n",
       "         'construction': 0.0003118178983473651,\n",
       "         'synthesis': 0.0003118178983473651,\n",
       "         'belief': 0.0003118178983473651,\n",
       "         'symbolic': 0.0012472715933894605,\n",
       "         'reason': 0.0003118178983473651,\n",
       "         'language': 0.0006236357966947302,\n",
       "         'modification': 0.0006236357966947302,\n",
       "         'cellular': 0.0003118178983473651,\n",
       "         'functional': 0.0006236357966947302,\n",
       "         'plausibility': 0.0003118178983473651,\n",
       "         'mutli': 0.0003118178983473651,\n",
       "         'portfolio': 0.0003118178983473651,\n",
       "         'density': 0.0006236357966947302,\n",
       "         'tool': 0.0009354536950420954,\n",
       "         'brain': 0.0003118178983473651,\n",
       "         'different': 0.0003118178983473651,\n",
       "         'topological': 0.0009354536950420954,\n",
       "         'pareto': 0.0006236357966947302,\n",
       "         'winner': 0.0003118178983473651,\n",
       "         'disembodied': 0.0003118178983473651,\n",
       "         'thermodynamical': 0.0003118178983473651,\n",
       "         'notation': 0.0003118178983473651,\n",
       "         'linked': 0.0003118178983473651,\n",
       "         'set': 0.0003118178983473651,\n",
       "         'counterexample': 0.0006236357966947302,\n",
       "         'mip': 0.0003118178983473651,\n",
       "         'computer': 0.0012472715933894605,\n",
       "         'probability': 0.0003118178983473651,\n",
       "         'spatio': 0.0003118178983473651,\n",
       "         'k': 0.0003118178983473651,\n",
       "         'savage': 0.0003118178983473651,\n",
       "         'dikw': 0.0003118178983473651,\n",
       "         'simulated': 0.0006236357966947302,\n",
       "         'reinforcement': 0.0012472715933894605,\n",
       "         'popperian': 0.0003118178983473651,\n",
       "         'partitioning': 0.0003118178983473651,\n",
       "         'reasoning': 0.0003118178983473651,\n",
       "         'diversified': 0.0003118178983473651,\n",
       "         'focal': 0.0003118178983473651,\n",
       "         'thorough': 0.0003118178983473651,\n",
       "         'decidable': 0.0006236357966947302,\n",
       "         'vision': 0.0009354536950420954,\n",
       "         'labelling': 0.0003118178983473651,\n",
       "         'policy': 0.0003118178983473651,\n",
       "         'generally': 0.0003118178983473651,\n",
       "         'double': 0.0006236357966947302,\n",
       "         'berkeley': 0.0003118178983473651,\n",
       "         'total': 0.0006236357966947302,\n",
       "         'reliability': 0.0006236357966947302,\n",
       "         'cyber': 0.0003118178983473651,\n",
       "         'swift': 0.0003118178983473651,\n",
       "         'brandom': 0.0003118178983473651,\n",
       "         'risk': 0.0003118178983473651,\n",
       "         'bagging': 0.0003118178983473651,\n",
       "         'dependent': 0.0003118178983473651,\n",
       "         'complexity': 0.0003118178983473651,\n",
       "         'reversible': 0.0003118178983473651,\n",
       "         'rank': 0.0003118178983473651,\n",
       "         'wild': 0.0003118178983473651,\n",
       "         'bennett': 0.0003118178983473651,\n",
       "         'parzen': 0.0003118178983473651,\n",
       "         'truncated': 0.0003118178983473651,\n",
       "         'direct': 0.0006236357966947302,\n",
       "         'fused': 0.0003118178983473651,\n",
       "         'naive': 0.0003118178983473651,\n",
       "         'closed': 0.0009354536950420954,\n",
       "         'prior': 0.0003118178983473651,\n",
       "         'scale': 0.0009354536950420954,\n",
       "         'theoretically': 0.0003118178983473651,\n",
       "         'kernelized': 0.0003118178983473651,\n",
       "         'mutual': 0.0003118178983473651,\n",
       "         'ranking': 0.0003118178983473651,\n",
       "         'locally': 0.0009354536950420954,\n",
       "         'birth': 0.0003118178983473651,\n",
       "         'mutually': 0.0003118178983473651,\n",
       "         'relevance': 0.0003118178983473651,\n",
       "         'signature': 0.0003118178983473651,\n",
       "         'debiased': 0.0003118178983473651,\n",
       "         'summary': 0.0003118178983473651,\n",
       "         'composite': 0.0003118178983473651,\n",
       "         'higher': 0.0006236357966947302,\n",
       "         'multilateral': 0.0003118178983473651,\n",
       "         'keygraph': 0.0003118178983473651,\n",
       "         'dyadic': 0.0003118178983473651,\n",
       "         'multiple': 0.0012472715933894605,\n",
       "         'face': 0.0012472715933894605,\n",
       "         'facial': 0.0003118178983473651,\n",
       "         'united': 0.0003118178983473651,\n",
       "         'multimodal': 0.0009354536950420954,\n",
       "         'report': 0.0003118178983473651,\n",
       "         'co': 0.0003118178983473651,\n",
       "         'variation': 0.0003118178983473651,\n",
       "         'proposition': 0.0003118178983473651,\n",
       "         'synergistic': 0.0003118178983473651,\n",
       "         '$': 0.0003118178983473651,\n",
       "         'panorama': 0.0003118178983473651,\n",
       "         'meshless': 0.0003118178983473651,\n",
       "         'polygon': 0.0003118178983473651,\n",
       "         'multilevel': 0.0006236357966947302,\n",
       "         'gaussian': 0.0009354536950420954,\n",
       "         'video': 0.0003118178983473651,\n",
       "         'multilinear': 0.0003118178983473651,\n",
       "         'revisit': 0.0009354536950420954,\n",
       "         'ga': 0.0006236357966947302,\n",
       "         'miniature': 0.0003118178983473651,\n",
       "         'reduced': 0.0003118178983473651,\n",
       "         'prototyping': 0.0003118178983473651,\n",
       "         'ray': 0.0003118178983473651,\n",
       "         'gabor': 0.0006236357966947302,\n",
       "         'reverse': 0.0006236357966947302,\n",
       "         'bottom': 0.0006236357966947302,\n",
       "         'combined': 0.0009354536950420954,\n",
       "         'concept': 0.0003118178983473651,\n",
       "         'gesture': 0.0003118178983473651,\n",
       "         'faster': 0.0006236357966947302,\n",
       "         'pooling': 0.0003118178983473651,\n",
       "         'clearer': 0.0003118178983473651,\n",
       "         'proximal': 0.0009354536950420954,\n",
       "         'multicomponent': 0.0003118178983473651,\n",
       "         'coarse': 0.0006236357966947302,\n",
       "         'massively': 0.0003118178983473651,\n",
       "         'picture': 0.0006236357966947302,\n",
       "         'century': 0.0003118178983473651,\n",
       "         'dense': 0.0003118178983473651,\n",
       "         'shapley': 0.0003118178983473651,\n",
       "         'multiresolution': 0.0006236357966947302,\n",
       "         'fractal': 0.0003118178983473651,\n",
       "         'holistic': 0.0006236357966947302,\n",
       "         '4d': 0.0003118178983473651,\n",
       "         'three': 0.0009354536950420954,\n",
       "         'transportation': 0.0003118178983473651,\n",
       "         'cnn': 0.0006236357966947302,\n",
       "         'map': 0.0006236357966947302,\n",
       "         'detailed': 0.0003118178983473651,\n",
       "         'backward': 0.0003118178983473651,\n",
       "         'dnn': 0.0003118178983473651,\n",
       "         'discriminatively': 0.0003118178983473651,\n",
       "         'concave': 0.0003118178983473651,\n",
       "         'projected': 0.0003118178983473651,\n",
       "         'kinematic': 0.0003118178983473651,\n",
       "         'pursuit': 0.0003118178983473651,\n",
       "         'localisation': 0.0003118178983473651,\n",
       "         'patchmatch': 0.0003118178983473651,\n",
       "         'proximity': 0.0003118178983473651,\n",
       "         'good': 0.0003118178983473651,\n",
       "         'convolution': 0.0003118178983473651,\n",
       "         'procedural': 0.0003118178983473651,\n",
       "         'comment': 0.0009354536950420954,\n",
       "         'location': 0.0003118178983473651,\n",
       "         'nuclear': 0.0003118178983473651,\n",
       "         '3d': 0.0012472715933894605,\n",
       "         'labeling': 0.0003118178983473651,\n",
       "         'perceptually': 0.0003118178983473651,\n",
       "         'watershed': 0.0003118178983473651,\n",
       "         'kind': 0.0003118178983473651,\n",
       "         'spatiotemporal': 0.0006236357966947302,\n",
       "         'human': 0.0012472715933894605,\n",
       "         'region': 0.0003118178983473651,\n",
       "         'harmony': 0.0003118178983473651,\n",
       "         'guided': 0.0003118178983473651,\n",
       "         'jointly': 0.0003118178983473651,\n",
       "         'weighting': 0.0003118178983473651,\n",
       "         'wavelet': 0.0003118178983473651,\n",
       "         'compromise': 0.0003118178983473651,\n",
       "         'reproducible': 0.0003118178983473651,\n",
       "         'product': 0.0003118178983473651,\n",
       "         'detail': 0.0003118178983473651,\n",
       "         'lbp': 0.0003118178983473651,\n",
       "         'concatenating': 0.0003118178983473651,\n",
       "         'transfer': 0.0003118178983473651,\n",
       "         'saak': 0.0003118178983473651,\n",
       "         'taught': 0.0003118178983473651,\n",
       "         'color': 0.0003118178983473651,\n",
       "         'smartphone': 0.0003118178983473651,\n",
       "         'pose': 0.0003118178983473651,\n",
       "         'perceptual': 0.0003118178983473651,\n",
       "         '+': 0.0003118178983473651,\n",
       "         'frequency': 0.0003118178983473651,\n",
       "         'performance': 0.0003118178983473651,\n",
       "         'bidirectional': 0.0003118178983473651,\n",
       "         'foreground': 0.0003118178983473651,\n",
       "         'rapidly': 0.0003118178983473651,\n",
       "         'log': 0.0003118178983473651,\n",
       "         'collaborative': 0.0009354536950420954,\n",
       "         'weighted': 0.0006236357966947302,\n",
       "         'twofold': 0.0003118178983473651,\n",
       "         'resilient': 0.0003118178983473651,\n",
       "         'retinal': 0.0003118178983473651,\n",
       "         'predictor': 0.0003118178983473651,\n",
       "         'structural': 0.0006236357966947302,\n",
       "         'temporally': 0.0003118178983473651,\n",
       "         'smoke': 0.0003118178983473651,\n",
       "         'massive': 0.0003118178983473651,\n",
       "         'quadratic': 0.0003118178983473651,\n",
       "         'limit': 0.0003118178983473651,\n",
       "         'mirroring': 0.0003118178983473651,\n",
       "         'chaid': 0.0003118178983473651,\n",
       "         'credit': 0.0003118178983473651,\n",
       "         'drifting': 0.0003118178983473651,\n",
       "         'sober': 0.0003118178983473651,\n",
       "         'converged': 0.0003118178983473651,\n",
       "         'uniqueness': 0.0003118178983473651,\n",
       "         'last': 0.0003118178983473651,\n",
       "         'quorum': 0.0003118178983473651,\n",
       "         'lower': 0.0006236357966947302,\n",
       "         'canonical': 0.0003118178983473651,\n",
       "         'batchwise': 0.0003118178983473651,\n",
       "         'propound': 0.0003118178983473651,\n",
       "         'hash': 0.0003118178983473651,\n",
       "         'mixtures': 0.0003118178983473651,\n",
       "         'semidefinite': 0.0003118178983473651,\n",
       "         'tree': 0.0003118178983473651,\n",
       "         'distribution': 0.0003118178983473651,\n",
       "         'shapelet': 0.0003118178983473651,\n",
       "         'smoothed': 0.0003118178983473651,\n",
       "         'hardware': 0.0003118178983473651,\n",
       "         'continuation': 0.0003118178983473651,\n",
       "         'block': 0.0003118178983473651,\n",
       "         'reductions': 0.0003118178983473651,\n",
       "         'role': 0.0003118178983473651,\n",
       "         'pyramidal': 0.0003118178983473651,\n",
       "         'component': 0.0003118178983473651,\n",
       "         'biologically': 0.0006236357966947302,\n",
       "         'hitchhiker': 0.0003118178983473651,\n",
       "         'weight': 0.0003118178983473651,\n",
       "         'multiset': 0.0003118178983473651,\n",
       "         'doubly': 0.0003118178983473651,\n",
       "         'java': 0.0006236357966947302,\n",
       "         'normative': 0.0006236357966947302,\n",
       "         'wake': 0.0003118178983473651,\n",
       "         'tale': 0.0003118178983473651,\n",
       "         'deductive': 0.0003118178983473651,\n",
       "         'plan': 0.0003118178983473651,\n",
       "         'spanish': 0.0003118178983473651,\n",
       "         'psycholinguistically': 0.0003118178983473651,\n",
       "         'corrective': 0.0003118178983473651,\n",
       "         'cnl': 0.0003118178983473651,\n",
       "         'type': 0.0003118178983473651,\n",
       "         'lexical': 0.0003118178983473651,\n",
       "         'lemma': 0.0003118178983473651,\n",
       "         'broadcast': 0.0003118178983473651,\n",
       "         'mood': 0.0003118178983473651,\n",
       "         'maturity': 0.0003118178983473651,\n",
       "         'hackathon': 0.0003118178983473651,\n",
       "         'german': 0.0003118178983473651,\n",
       "         'tidy': 0.0003118178983473651,\n",
       "         'neurobiologically': 0.0003118178983473651,\n",
       "         'neuron': 0.0003118178983473651,\n",
       "         'kdv': 0.0003118178983473651,\n",
       "         'small': 0.0003118178983473651,\n",
       "         'biological': 0.0003118178983473651,\n",
       "         'memcomputing': 0.0003118178983473651,\n",
       "         'scheme': 0.0003118178983473651,\n",
       "         'discontinuous': 0.0003118178983473651,\n",
       "         'metaprogramming': 0.0003118178983473651,\n",
       "         'norm': 0.0003118178983473651,\n",
       "         'further': 0.0003118178983473651,\n",
       "         'tableau': 0.0003118178983473651,\n",
       "         'denotational': 0.0003118178983473651,\n",
       "         'modal': 0.0003118178983473651,\n",
       "         'spectrum': 0.0003118178983473651,\n",
       "         'parameterised': 0.0003118178983473651,\n",
       "         'situation': 0.0003118178983473651,\n",
       "         'sequent': 0.0003118178983473651,\n",
       "         'chr': 0.0003118178983473651,\n",
       "         'tcsp': 0.0003118178983473651,\n",
       "         'fp': 0.0003118178983473651,\n",
       "         'link': 0.0003118178983473651,\n",
       "         'geometry': 0.0003118178983473651,\n",
       "         'simulation': 0.0003118178983473651,\n",
       "         'backtracking': 0.0003118178983473651,\n",
       "         'pseudo': 0.0003118178983473651,\n",
       "         'remark': 0.0003118178983473651,\n",
       "         'discrete': 0.0003118178983473651,\n",
       "         'dynamical': 0.0003118178983473651,\n",
       "         'version': 0.0003118178983473651,\n",
       "         'dichotomy': 0.0006236357966947302,\n",
       "         'cookbook': 0.0003118178983473651,\n",
       "         'personalized': 0.0003118178983473651,\n",
       "         'rough': 0.0003118178983473651,\n",
       "         'hypergraph': 0.0003118178983473651,\n",
       "         'little': 0.0003118178983473651,\n",
       "         'factorial': 0.0003118178983473651,\n",
       "         'superposition': 0.0003118178983473651,\n",
       "         'transformational': 0.0003118178983473651,\n",
       "         'gps': 0.0003118178983473651,\n",
       "         'conflict': 0.0003118178983473651,\n",
       "         'criterion': 0.0003118178983473651,\n",
       "         'trust': 0.0003118178983473651,\n",
       "         'sufficiently': 0.0003118178983473651,\n",
       "         'community': 0.0003118178983473651,\n",
       "         'microkernel': 0.0003118178983473651,\n",
       "         'refined': 0.0003118178983473651,\n",
       "         'vague': 0.0003118178983473651,\n",
       "         'multistage': 0.0003118178983473651,\n",
       "         'gradient': 0.0006236357966947302,\n",
       "         'resolution': 0.0003118178983473651,\n",
       "         'coordinated': 0.0003118178983473651,\n",
       "         'tabu': 0.0003118178983473651,\n",
       "         'csp': 0.0003118178983473651,\n",
       "         'synthetic': 0.0003118178983473651,\n",
       "         'signaling': 0.0003118178983473651,\n",
       "         'dematel': 0.0003118178983473651,\n",
       "         'programming': 0.0003118178983473651,\n",
       "         'centralized': 0.0003118178983473651,\n",
       "         'physician': 0.0003118178983473651,\n",
       "         'pre': 0.0003118178983473651,\n",
       "         'realistic': 0.0003118178983473651,\n",
       "         'hypercat': 0.0003118178983473651,\n",
       "         'service': 0.0003118178983473651,\n",
       "         'tutor': 0.0003118178983473651,\n",
       "         'simulator': 0.0003118178983473651,\n",
       "         'pig': 0.0003118178983473651,\n",
       "         'streaming': 0.0003118178983473651,\n",
       "         'foundry': 0.0003118178983473651,\n",
       "         'd': 0.0003118178983473651,\n",
       "         'road': 0.0003118178983473651,\n",
       "         'nonconformity': 0.0003118178983473651,\n",
       "         'path': 0.0006236357966947302,\n",
       "         'sentiment': 0.0003118178983473651,\n",
       "         'secure': 0.0003118178983473651,\n",
       "         'bengali': 0.0003118178983473651,\n",
       "         'pointillism': 0.0003118178983473651,\n",
       "         'hindi': 0.0003118178983473651,\n",
       "         'preadapted': 0.0003118178983473651,\n",
       "         'stronger': 0.0003118178983473651,\n",
       "         'rigorous': 0.0003118178983473651,\n",
       "         'medial': 0.0003118178983473651,\n",
       "         'parametric': 0.0003118178983473651,\n",
       "         'invertible': 0.0003118178983473651,\n",
       "         'phase': 0.0003118178983473651,\n",
       "         'missing': 0.0003118178983473651,\n",
       "         'session': 0.0003118178983473651,\n",
       "         'health': 0.0003118178983473651,\n",
       "         'hilbert': 0.0003118178983473651,\n",
       "         'matlab': 0.0003118178983473651,\n",
       "         'microwave': 0.0003118178983473651,\n",
       "         '8': 0.0003118178983473651,\n",
       "         'fresnelet': 0.0003118178983473651,\n",
       "         'narrative': 0.0003118178983473651,\n",
       "         'specialized': 0.0003118178983473651,\n",
       "         'message': 0.0003118178983473651,\n",
       "         'feasible': 0.0003118178983473651,\n",
       "         'multistep': 0.0003118178983473651,\n",
       "         'multiphase': 0.0003118178983473651,\n",
       "         'gmm': 0.0003118178983473651,\n",
       "         'nonlocal': 0.0003118178983473651,\n",
       "         '58': 0.0003118178983473651,\n",
       "         'glimpse': 0.0003118178983473651,\n",
       "         'lagrangian': 0.0003118178983473651,\n",
       "         'clever': 0.0003118178983473651,\n",
       "         'filter': 0.0003118178983473651,\n",
       "         'selectional': 0.0003118178983473651,\n",
       "         'line': 0.0003118178983473651,\n",
       "         'pde': 0.0003118178983473651,\n",
       "         'relational': 0.0003118178983473651,\n",
       "         'delta': 0.0003118178983473651,\n",
       "         'gentle': 0.0003118178983473651,\n",
       "         'variant': 0.0003118178983473651,\n",
       "         'tail': 0.0003118178983473651,\n",
       "         'technical': 0.0003118178983473651,\n",
       "         'comparism': 0.0003118178983473651,\n",
       "         'movie': 0.0003118178983473651,\n",
       "         'route': 0.0003118178983473651,\n",
       "         'robustica': 0.0003118178983473651,\n",
       "         'provably': 0.0003118178983473651,\n",
       "         'smoothing': 0.0003118178983473651,\n",
       "         'mapreduce': 0.0003118178983473651})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.get_possible_next_tokens('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,4,2,3,4])\n",
    "y=np.argwhere(x==max(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[y]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 3, 1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "cellId": "sgbatlm9vzb4z889fho7"
   },
   "outputs": [],
   "source": [
    "def get_next_token(lm, prefix, temperature=1.0):\n",
    "    \"\"\"\n",
    "    return next token after prefix;\n",
    "    :param temperature: samples proportionally to lm probabilities ^ (1 / temperature)\n",
    "        if temperature == 0, always takes most likely token. Break ties arbitrarily.\n",
    "    \"\"\"\n",
    "    elements = np.array(list(lm.get_possible_next_tokens(prefix).keys())) # tokens from which to sample\n",
    "    # if temperature == 0: # if temperature == 0, always takes most likely token. Break ties arbitrarily.\n",
    "    #     probabilities = np.array(list(lm.get_possible_next_tokens(prefix).values())) # get probabilites for next tokens from the LM\n",
    "    #     sample_from = np.argwhere(probabilities==max(probabilities))\n",
    "    #     if len(sample_from)==1:\n",
    "    #         print('a')\n",
    "    #         return elements[sample_from]\n",
    "    #     else:\n",
    "    #         return np.random.choice(elements[sample_from])\n",
    "    #     # print(elements[np.argwhere(probabilities==max(probabilities))][0])\n",
    "    #     # return random.sample(elements[np.argwhere(probabilities==max(probabilities))][0],1) # pick out of the elements that have top probability\n",
    "    # else:\n",
    "    if temperature == 0:\n",
    "        temperature = 0.01\n",
    "    probabilities = np.array([p**(1/temperature) for p in lm.get_possible_next_tokens(prefix).values()]) # temp-scale the probs\n",
    "    probabilities /= sum(probabilities) # normalise the temperature-scaled prob dist.\n",
    "        \n",
    "    return np.random.choice(elements, p=probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "cellId": "98l40131wjtd5xbdm5b2nr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks nice!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "test_freqs = Counter([get_next_token(lm, 'there have') for _ in range(10000)])\n",
    "assert 250 < test_freqs['not'] < 450\n",
    "assert 8500 < test_freqs['been'] < 9500\n",
    "assert 1 < test_freqs['lately'] < 200\n",
    "\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=1.0) for _ in range(10000)])\n",
    "assert 1500 < test_freqs['learning'] < 3000\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=0.5) for _ in range(10000)])\n",
    "assert 8000 < test_freqs['learning'] < 9000\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=0.0) for _ in range(10000)])\n",
    "assert test_freqs['learning'] == 10000\n",
    "\n",
    "print(\"Looks nice!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ux4n8iq523n4s3ftrelhxj"
   },
   "source": [
    "Let's have fun with this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "cellId": "1nnnycga61rijt6nd8zai"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial intelligence , and it is only a cpu . _EOS_\n"
     ]
    }
   ],
   "source": [
    "prefix = 'artificial' # <- your ideas :)\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += ' ' + get_next_token(lm, prefix)\n",
    "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
    "        break\n",
    "        \n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "cellId": "pxyjsv3b7r8thdfxlgitl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bridging the gap between the proposed approach . _EOS_\n"
     ]
    }
   ],
   "source": [
    "prefix = 'bridging the' # <- more of your ideas\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += ' ' + get_next_token(lm, prefix, temperature=0.5)\n",
    "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
    "        break\n",
    "        \n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "2n90bscmzfko0qnctp7ysc"
   },
   "source": [
    "__More in the homework:__ nucleous sampling, top-k sampling, beam search(not for the faint of heart)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3gdmey7g8at5n5c5x4gayh"
   },
   "source": [
    "### Evaluating language models: perplexity (1point)\n",
    "\n",
    "Perplexity is a measure of how well does your model approximate true probability distribution behind data. __Smaller perplexity = better model__.\n",
    "\n",
    "To compute perplexity on one sentence, use:\n",
    "$$\n",
    "    {\\mathbb{P}}(w_1 \\dots w_N) = P(w_1, \\dots, w_N)^{-\\frac1N} = \\left( \\prod_t P(w_t \\mid w_{t - n}, \\dots, w_{t - 1})\\right)^{-\\frac1N},\n",
    "$$\n",
    "\n",
    "\n",
    "On the corpora level, perplexity is a product of probabilities of all tokens in all sentences to the power of 1, divided by __total length of all sentences__ in corpora.\n",
    "\n",
    "This number can quickly get too small for float32/float64 precision, so we recommend you to first compute log-perplexity (from log-probabilities) and then take the exponent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "5hp010xyzzb4vqewo1bhny"
   },
   "outputs": [],
   "source": [
    "def perplexity(lm, lines, min_logprob=np.log(10 ** -50.)):\n",
    "    \"\"\"\n",
    "    :param lines: a list of strings with space-separated tokens\n",
    "    :param min_logprob: if log(P(w | ...)) is smaller than min_logprop, set it equal to min_logrob\n",
    "    :returns: corpora-level perplexity - a single scalar number from the formula above\n",
    "    \n",
    "    Note: do not forget to compute P(w_first | empty) and P(eos | full_sequence)\n",
    "    \n",
    "    PLEASE USE lm.get_next_token_prob and NOT lm.get_possible_next_tokens\n",
    "    \"\"\"\n",
    "    <YOUR CODE>\n",
    "    \n",
    "    return <...>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "8b689bobhkey04x7pabupj"
   },
   "outputs": [],
   "source": [
    "lm1 = NGramLanguageModel(dummy_lines, n=1)\n",
    "lm3 = NGramLanguageModel(dummy_lines, n=3)\n",
    "lm10 = NGramLanguageModel(dummy_lines, n=10)\n",
    "\n",
    "ppx1 = perplexity(lm1, dummy_lines)\n",
    "ppx3 = perplexity(lm3, dummy_lines)\n",
    "ppx10 = perplexity(lm10, dummy_lines)\n",
    "ppx_missing = perplexity(lm3, ['the jabberwock , with eyes of flame , '])  # thanks, L. Carrol\n",
    "\n",
    "print(\"Perplexities: ppx1=%.3f ppx3=%.3f ppx10=%.3f\" % (ppx1, ppx3, ppx10))\n",
    "\n",
    "assert all(0 < ppx < 500 for ppx in (ppx1, ppx3, ppx10)), \"perplexity should be nonnegative and reasonably small\"\n",
    "assert ppx1 > ppx3 > ppx10, \"higher N models should overfit and \"\n",
    "assert np.isfinite(ppx_missing) and ppx_missing > 10 ** 6, \"missing words should have large but finite perplexity. \" \\\n",
    "    \" Make sure you use min_logprob right\"\n",
    "assert np.allclose([ppx1, ppx3, ppx10], (318.2132342216302, 1.5199996213739575, 1.1838145037901249))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ypc4lks4vs1li908fqi8"
   },
   "source": [
    "Now let's measure the actual perplexity: we'll split the data into train and test and score model on test data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "tjnehsem2lmijkg2lto4w"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_lines, test_lines = train_test_split(lines, test_size=0.25, random_state=42)\n",
    "\n",
    "for n in (1, 2, 3):\n",
    "    lm = NGramLanguageModel(n=n, lines=train_lines)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "38nfbfkpzgfxik8kccyt1l"
   },
   "outputs": [],
   "source": [
    "# whoops, it just blew up :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "oopn2o57wxm9vbxzycytce"
   },
   "source": [
    "### LM Smoothing\n",
    "\n",
    "The problem with our simple language model is that whenever it encounters an n-gram it has never seen before, it assigns it with the probabilitiy of 0. Every time this happens, perplexity explodes.\n",
    "\n",
    "To battle this issue, there's a technique called __smoothing__. The core idea is to modify counts in a way that prevents probabilities from getting too low. The simplest algorithm here is Additive smoothing (aka [Lapace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)):\n",
    "\n",
    "$$ P(w_t | prefix) = { Count(prefix, w_t) + \\delta \\over \\sum_{\\hat w} (Count(prefix, \\hat w) + \\delta) } $$\n",
    "\n",
    "If counts for a given prefix are low, additive smoothing will adjust probabilities to a more uniform distribution. Not that the summation in the denominator goes over _all words in the vocabulary_.\n",
    "\n",
    "Here's an example code we've implemented for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ioh26rlov6g8l2ssj1c8pm"
   },
   "outputs": [],
   "source": [
    "class LaplaceLanguageModel(NGramLanguageModel): \n",
    "    \"\"\" this code is an example, no need to change anything \"\"\"\n",
    "    def __init__(self, lines, n, delta=1.0):\n",
    "        self.n = n\n",
    "        counts = count_ngrams(lines, self.n)\n",
    "        self.vocab = set(token for token_counts in counts.values() for token in token_counts)\n",
    "        self.probs = defaultdict(Counter)\n",
    "\n",
    "        for prefix in counts:\n",
    "            token_counts = counts[prefix]\n",
    "            total_count = sum(token_counts.values()) + delta * len(self.vocab)\n",
    "            self.probs[prefix] = {token: (token_counts[token] + delta) / total_count\n",
    "                                          for token in token_counts}\n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        token_probs = super().get_possible_next_tokens(prefix)\n",
    "        missing_prob_total = 1.0 - sum(token_probs.values())\n",
    "        missing_prob = missing_prob_total / max(1, len(self.vocab) - len(token_probs))\n",
    "        return {token: token_probs.get(token, missing_prob) for token in self.vocab}\n",
    "    \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        token_probs = super().get_possible_next_tokens(prefix)\n",
    "        if next_token in token_probs:\n",
    "            return token_probs[next_token]\n",
    "        else:\n",
    "            missing_prob_total = 1.0 - sum(token_probs.values())\n",
    "            missing_prob_total = max(0, missing_prob_total) # prevent rounding errors\n",
    "            return missing_prob_total / max(1, len(self.vocab) - len(token_probs))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "90vsann3920ie05r2blbmi",
    "execution_id": "3868303d-0bb9-42c6-a9a8-dcf485c8220c"
   },
   "source": [
    "**Disclaimer**: the implementation above assumes all words unknown within a given context to be equally likely, *as well as the words outside of vocabulary*. Therefore, its' perplexity will be lower than it should when encountering such words. Therefore, comparing it with a model with less unknown words will not be fair. When implementing your own smoothing, you may handle this by adding a virtual `UNK` token of non-zero probability. Technically, this will result in a model where probabilities do not add up to $1$, but it is close enough for a practice excercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "3xvxkdxcmfqucruyt66mdc"
   },
   "outputs": [],
   "source": [
    "#test that it's a valid probability model\n",
    "for n in (1, 2, 3):\n",
    "    dummy_lm = LaplaceLanguageModel(dummy_lines, n=n)\n",
    "    assert np.allclose(sum([dummy_lm.get_next_token_prob('a', w_i) for w_i in dummy_lm.vocab]), 1), \"I told you not to break anything! :)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "j6zqa50koitjjri9ipd8ec"
   },
   "outputs": [],
   "source": [
    "for n in (1, 2, 3):\n",
    "    lm = LaplaceLanguageModel(train_lines, n=n, delta=0.1)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "pjuqt30jcerwbz1ym9zv1"
   },
   "outputs": [],
   "source": [
    "# optional: try to sample tokens from such a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3b8s1y9uls4fosu3yp28gg"
   },
   "source": [
    "### Kneser-Ney smoothing (2 points)\n",
    "\n",
    "Additive smoothing is simple, reasonably good but definitely not a State of The Art algorithm.\n",
    "\n",
    "\n",
    "Your final task in this notebook is to implement [Kneser-Ney](https://en.wikipedia.org/wiki/Kneser%E2%80%93Ney_smoothing) smoothing.\n",
    "\n",
    "It can be computed recurrently, for n>1:\n",
    "\n",
    "$$P_{kn}(w_t | prefix_{n-1}) = { \\max(0, Count(prefix_{n-1}, w_t) - \\delta) \\over \\sum_{\\hat w} Count(prefix_{n-1}, \\hat w)} + \\lambda_{prefix_{n-1}} \\cdot P_{kn}(w_t | prefix_{n-2})$$\n",
    "\n",
    "where\n",
    "- $prefix_{n-1}$ is a tuple of {n-1} previous tokens\n",
    "- $lambda_{prefix_{n-1}}$ is a normalization constant chosen so that probabilities add up to 1\n",
    "- Unigram $P_{kn}(w_t | prefix_{n-2})$ corresponds to Kneser Ney smoothing for {N-1}-gram language model.\n",
    "- Unigram $P_{kn}(w_t)$ is a special case: how likely it is to see x_t in an unfamiliar context\n",
    "\n",
    "See lecture slides or wiki for more detailed formulae.\n",
    "\n",
    "__Your task__ is to\n",
    "- implement KneserNeyLanguageModel\n",
    "- test it on 1-3 gram language models\n",
    "- find optimal (within reason) smoothing delta for 3-gram language model with Kneser-Ney smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "2ix7kzw02v30oye55322all"
   },
   "outputs": [],
   "source": [
    "class KneserNeyLanguageModel(NGramLanguageModel): \n",
    "    \"\"\" A template for Kneser-Ney language model. Default delta may be suboptimal. \"\"\"\n",
    "    def __init__(self, lines, n, delta=1.0):\n",
    "        self.n = n\n",
    "        <YOUR CODE>\n",
    "        \n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        < YOUR CODE >\n",
    "        \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "lsk91832qbmdt7x1q0a8z4"
   },
   "outputs": [],
   "source": [
    "#test that it's a valid probability model\n",
    "for n in (1, 2, 3):\n",
    "    dummy_lm = KneserNeyLanguageModel(dummy_lines, n=n)\n",
    "    assert np.allclose(sum([dummy_lm.get_next_token_prob('a', w_i) for w_i in dummy_lm.vocab]), 1), \"I told you not to break anything! :)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "pp3jtkk9annp1qkou58x1b"
   },
   "outputs": [],
   "source": [
    "for n in (1, 2, 3):\n",
    "    lm = KneserNeyLanguageModel(train_lines, n=n, smoothing=<...>)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "notebookId": "53997d2d-afb8-4477-8874-b6d46299f06c",
  "notebookPath": "seminar.ipynb",
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
